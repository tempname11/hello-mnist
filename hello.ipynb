{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# SETTINGS\n",
    "\n",
    "learning_rate = 1e-2\n",
    "torch.manual_seed(42)\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "\tdevice = 'cuda'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n",
      "torch.float32 torch.uint8\n"
     ]
    }
   ],
   "source": [
    "mnist_train = torchvision.datasets.MNIST('.', train=True, download=True)\n",
    "mnist_test = torchvision.datasets.MNIST('.', train=False, download=True)\n",
    "\n",
    "data_train = mnist_train.data.to(device).float()\n",
    "data_test = mnist_test.data.to(device)\n",
    "\n",
    "target_train = mnist_train.targets.to(device).float()\n",
    "target_test = mnist_test.targets.to(device)\n",
    "\n",
    "print(data_train.shape, data_test.shape)\n",
    "print(data_train.dtype, data_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.linear1 = nn.Linear(784, 800)\n",
    "\t\tself.linear2 = nn.Linear(800, 10)\n",
    "\t\t\n",
    "\tdef forward(self, x, y=None):\n",
    "\t\tr = x.view(-1, 784)\n",
    "\t\tr = F.relu(self.linear1(r))\n",
    "\t\tr = self.linear2(r)\n",
    "\t\tif y is None:\n",
    "\t\t\tloss = None\n",
    "\t\telse:\n",
    "\t\t\tloss = F.cross_entropy(r, y)\n",
    "\t\treturn r, loss\n",
    "\n",
    "\tdef predict(self, x):\n",
    "\t\tlogits, _ = self.forward(x)\n",
    "\t\treturn logits.argmax()\n",
    "\n",
    "model = Model().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\v7\\Repositories\\hello-mnist\\hello.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \t\tlosses[i] \u001b[39m=\u001b[39m loss\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \t\u001b[39mreturn\u001b[39;00m losses\u001b[39m.\u001b[39mmean()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m estimate_loss(\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m), estimate_loss(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\v7\\miniconda3\\envs\\my-notebook-env\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32mc:\\Users\\v7\\Repositories\\hello-mnist\\hello.ipynb Cell 5\u001b[0m in \u001b[0;36mestimate_loss\u001b[1;34m(split)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(estimation_iters):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \tx, y \u001b[39m=\u001b[39m get_batch(split)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \tlogits, loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(x, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \tlosses[i] \u001b[39m=\u001b[39m loss\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mreturn\u001b[39;00m losses\u001b[39m.\u001b[39mmean()\n",
      "\u001b[1;32mc:\\Users\\v7\\Repositories\\hello-mnist\\hello.ipynb Cell 5\u001b[0m in \u001b[0;36mModel.forward\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \tloss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \tloss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mcross_entropy(r, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m r, loss\n",
      "File \u001b[1;32mc:\\Users\\v7\\miniconda3\\envs\\my-notebook-env\\lib\\site-packages\\torch\\nn\\functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3012\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3013\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3014\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "estimation_iters = 100\n",
    "estimation_batch = 32\n",
    "\n",
    "def get_batch(split):\n",
    "\tdata = data_train if split == 'train' else data_test\n",
    "\ttarget = target_train if split == 'train' else data_test\n",
    "\tix = torch.randint(0, len(data), (estimation_batch,))\n",
    "\tx = torch.stack([data[i] for i in ix])\n",
    "\ty = torch.stack([target[i] for i in ix])\n",
    "\treturn x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(split):\n",
    "\tlosses = torch.zeros(estimation_iters)\n",
    "\tfor i in range(estimation_iters):\n",
    "\t\tx, y = get_batch(split)\n",
    "\t\tlogits, loss = model.forward(x, y)\n",
    "\t\tlosses[i] = loss\n",
    "\treturn losses.mean()\n",
    "\n",
    "estimate_loss('train'), estimate_loss('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iters = 10000\n",
    "training_batch = 32\n",
    "eval_interval = 1000\n",
    "for iter in range(max_iters):\n",
    "\tif (iter % eval_interval) == 0:\n",
    "\t\tprint(f'iter {iter}: loss={estimate_loss()}')\n",
    "\tx = data_train.data[iter]\n",
    "\ty = data_train.targets[iter]\n",
    "\tlogits, loss = model(x, y)\n",
    "\toptimizer.zero_grad()\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_one(index):\n",
    "\tprint(model.predict(data_train.data[index].to(device).float()))\n",
    "\treturn images_train[index][0]\n",
    "\n",
    "predict_one(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-notebook-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
