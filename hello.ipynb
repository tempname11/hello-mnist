{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# SETTINGS\n",
    "learning_rate = 1e-2\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "\tdevice = 'cuda'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n",
      "torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "mnist_train = torchvision.datasets.MNIST('.', train=True, download=True)\n",
    "mnist_test = torchvision.datasets.MNIST('.', train=False, download=True)\n",
    "\n",
    "data_train = mnist_train.data.to(device).float()\n",
    "data_test = mnist_test.data.to(device).float()\n",
    "\n",
    "target_train = mnist_train.targets.to(device)\n",
    "target_test = mnist_test.targets.to(device)\n",
    "\n",
    "print(data_train.shape, data_test.shape)\n",
    "print(data_train.dtype, data_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.net = nn.Sequential(\n",
    "\t\t\tnn.Linear(784, 800),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(800, 10),\n",
    "\t\t\tnn.Dropout(0.2),\n",
    "\t\t)\n",
    "\t\t\n",
    "\tdef forward(self, x, y=None):\n",
    "\t\tr = x.view(-1, 784)\n",
    "\t\tr = self.net(r)\n",
    "\t\t# r = F.relu(self.linear1(r))\n",
    "\t\t# r = self.linear2(r)\n",
    "\t\tif y is None:\n",
    "\t\t\tloss = None\n",
    "\t\telse:\n",
    "\t\t\tloss = F.cross_entropy(r, y)\n",
    "\t\treturn r, loss\n",
    "\n",
    "model = Model().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_iters = 4\n",
    "estimation_batch = 256\n",
    "\n",
    "def get_split(split):\n",
    "\tdata = data_train if split == 'train' else data_test\n",
    "\ttarget = target_train if split == 'train' else target_test\n",
    "\treturn data, target\n",
    "\n",
    "def get_batch(batch_size, split):\n",
    "\tdata, target = get_split(split)\n",
    "\tix = torch.randint(0, len(data), (batch_size,))\n",
    "\tx = torch.stack([data[i] for i in ix])\n",
    "\ty = torch.stack([target[i] for i in ix])\n",
    "\treturn x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(split = None):\n",
    "\tif split == None:\n",
    "\t\treturn estimate_loss('train'), estimate_loss('test')\n",
    "\tlosses = torch.zeros(estimation_iters)\n",
    "\tfor i in range(estimation_iters):\n",
    "\t\tx, y = get_batch(estimation_batch, split)\n",
    "\t\tlogits, loss = model.forward(x, y)\n",
    "\t\tlosses[i] = loss\n",
    "\treturn losses.mean().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def total_loss(split = None):\n",
    "\tif split == None:\n",
    "\t\treturn total_loss('train'), total_loss('test')\n",
    "\tdata, target = get_split(split)\n",
    "\tlosses = torch.zeros(len(data) // estimation_batch)\n",
    "\tfor i in range(len(data) // estimation_batch):\n",
    "\t\tlower = i * estimation_batch\n",
    "\t\tupper = min((i + 1) * estimation_batch, len(data))\n",
    "\t\tx = data[lower:upper]\n",
    "\t\ty = target[lower:upper]\n",
    "\t\tlogits, loss = model.forward(x, y)\n",
    "\t\tlosses[i] = loss\n",
    "\treturn losses.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: loss_train=1.9520652294158936, loss_test=1.925053358078003\n",
      "iter 10: loss_train=1.0562384128570557, loss_test=1.0887668132781982\n",
      "iter 20: loss_train=1.3194245100021362, loss_test=1.2008187770843506\n",
      "iter 30: loss_train=1.372653841972351, loss_test=1.0943793058395386\n",
      "iter 40: loss_train=1.1309252977371216, loss_test=1.0781770944595337\n",
      "iter 50: loss_train=1.1480441093444824, loss_test=0.91194748878479\n",
      "iter 60: loss_train=0.926904022693634, loss_test=1.0020917654037476\n",
      "iter 70: loss_train=1.1445530652999878, loss_test=1.0639041662216187\n",
      "iter 80: loss_train=0.8845636248588562, loss_test=1.0733591318130493\n",
      "iter 90: loss_train=0.9023007154464722, loss_test=0.9586383700370789\n"
     ]
    }
   ],
   "source": [
    "training_iters = 100\n",
    "training_batch = 64\n",
    "eval_interval = 10\n",
    "batch_losses = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for iter in range(training_iters):\n",
    "\tif (iter % eval_interval) == 0:\n",
    "\t\tloss_train, loss_test = estimate_loss()\n",
    "\t\ttest_losses.append(loss_test)\n",
    "\t\ttrain_losses.append(loss_train)\n",
    "\t\tprint(f'iter {iter}: loss_train={loss_train}, loss_test={loss_test}')\n",
    "\n",
    "\tx, y = get_batch(training_batch, 'train')\n",
    "\tlogits, loss = model(x, y)\n",
    "\toptimizer.zero_grad()\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\tbatch_losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1]) torch.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v7\\AppData\\Local\\Temp\\ipykernel_20104\\513220479.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch.multinomial(F.softmax(logits), 1)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\v7\\Repositories\\hello-mnist\\hello.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \tresult \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmultinomial(F\u001b[39m.\u001b[39msoftmax(logits), \u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \t\u001b[39mprint\u001b[39m(result\u001b[39m.\u001b[39mshape, result\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \t\u001b[39mif\u001b[39;00m result \u001b[39m==\u001b[39;49m target_test[i]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \t\taccuracy \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/v7/Repositories/hello-mnist/hello.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m accuracy \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data_test)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for i in range(len(data_test)):\n",
    "\t# result = model.predict(data_test[i])\n",
    "\tlogits, _ = model(x)\n",
    "\tresult = torch.multinomial(F.softmax(logits), 1)\n",
    "\tprint(result.shape, result.dtype)\n",
    "\tif result == target_test[i]:\n",
    "\t\taccuracy += 1\n",
    "\n",
    "accuracy /= len(data_test)\n",
    "loss = total_loss('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7413\n",
      "0.9198777675628662 0.3985677560153619\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "print(accuracy)\n",
    "print(loss, math.exp(-loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: 8, target: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA60lEQVR4nGNgGNpAtv3P/8X8WKU4sr/9+/fvnyE2Oa0d/15vsJVqE8OU4s59/W+bJHbbOCr+/SrhYWBgEGXBkGOs/vfEiYGBgUHxgzKGpPu/M0oMDAwMlj/eSKDL+f9+psrAwMDW+edfObqc7PnnyQwMDDa3/v07xIku2fsvl4FBqvvzlX/vhTBsvPZawm7i6x8t6X8rMeSEnvy8/e/n9Sj5j2exeHLzn9+3SxgEV30UwSLJYCPHwMDg9W8DNjkGBgYGBoGjr3CEHgMDg9+/aJxyqi9PsuOUrHqshFNO+ccsnHIMU6bjliMRAAC0Z04cW5gwhAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_one(index):\n",
    "\tprint(f'predict: {model.predict(data_test[index])}, target: {target_test[index]}')\n",
    "\treturn mnist_test[index][0]\n",
    "\n",
    "import random\n",
    "predict_one(random.randint(0, data_test.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-notebook-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
